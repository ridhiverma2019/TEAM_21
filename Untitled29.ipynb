{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7g-fCLb_bz59",
        "outputId": "e5a18aa4-954c-4496-90ec-7110e582abe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing pre_processing.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile pre_processing.py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "\n",
        "#------------------------------------------\n",
        "\n",
        "def preprocess_wine_data(wine_path):\n",
        "\n",
        "    print(\"Loading Wine dataset...\")\n",
        "\n",
        "    column_names = ['Class', 'Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash',\n",
        "                    'Magnesium', 'Total phenols', 'Flavanoids', 'Nonflavanoid phenols',\n",
        "                    'Proanthocyanins', 'Color intensity', 'Hue',\n",
        "                    'OD280/OD315 of diluted wines', 'Proline']\n",
        "\n",
        "    wine_df = pd.read_csv(wine_path, names=column_names)\n",
        "\n",
        "    print(f\"Wine dataset shape: {wine_df.shape}\")\n",
        "    print(\"First few rows of the wine dataset:\")\n",
        "    print(wine_df.head())\n",
        "\n",
        "\n",
        "    X_wine = wine_df.drop('Class', axis=1)\n",
        "    y_wine = wine_df['Class']\n",
        "\n",
        "\n",
        "    print(\"\\nPerforming outlier removal...\")\n",
        "    iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
        "    outlier_mask = iso_forest.fit_predict(X_wine) == 1\n",
        "\n",
        "    X_wine_clean = X_wine[outlier_mask]\n",
        "    y_wine_clean = y_wine[outlier_mask]\n",
        "\n",
        "    print(f\"Removed {X_wine.shape[0] - X_wine_clean.shape[0]} outliers\")\n",
        "    print(f\"Clean wine dataset shape: {X_wine_clean.shape}\")\n",
        "\n",
        "    print(\"\\nPerforming feature scaling...\")\n",
        "    scaler = StandardScaler()\n",
        "    X_wine_scaled = scaler.fit_transform(X_wine_clean)\n",
        "\n",
        "\n",
        "    print(\"\\nPerforming PCA dimensionality reduction...\")\n",
        "\n",
        "    pca = PCA(n_components=0.95, random_state=42)\n",
        "    X_wine_pca = pca.fit_transform(X_wine_scaled)\n",
        "\n",
        "    print(f\"Reduced dimensions: {X_wine_pca.shape[1]} components explain 95% of variance\")\n",
        "    print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
        "\n",
        "\n",
        "    if X_wine_pca.shape[1] == 2:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        for i in np.unique(y_wine_clean):\n",
        "            plt.scatter(X_wine_pca[y_wine_clean == i, 0], X_wine_pca[y_wine_clean == i, 1],\n",
        "                       label=f'Class {i}')\n",
        "        plt.legend()\n",
        "        plt.title('PCA of Wine Dataset (2 components)')\n",
        "        plt.xlabel('PC1')\n",
        "        plt.ylabel('PC2')\n",
        "        plt.show()\n",
        "\n",
        "    return X_wine_pca, y_wine_clean, pca, scaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjVWzPpnb2cm",
        "outputId": "e6293ec0-acdb-48f1-d573-5f021af950e9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-25.1.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.6.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (24.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.6.0)\n",
            "Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-25.1.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-25.1.0 scikit-optimize-0.10.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import adjusted_rand_score\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
        "\n",
        "def train_evaluate_gmm(X, dataset_name, y=None, n_components=3, subsample_size=10000):\n",
        "\n",
        "    print(f\"\\n===== Training GMM on {dataset_name} Dataset =====\")\n",
        "\n",
        "    if X.shape[0] > subsample_size:\n",
        "        if y is not None:\n",
        "            X, y = resample(X, y, n_samples=subsample_size, random_state=42)\n",
        "        else:\n",
        "            X = resample(X, n_samples=subsample_size, random_state=42)\n",
        "\n",
        "\n",
        "    gmm = GaussianMixture(\n",
        "        n_components=n_components,\n",
        "        covariance_type='full',\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    gmm.fit(X)\n",
        "\n",
        "\n",
        "    labels = gmm.predict(X)\n",
        "\n",
        "\n",
        "    bic = gmm.bic(X)\n",
        "    aic = gmm.aic(X)\n",
        "\n",
        "\n",
        "    log_likelihood = gmm.score(X) * X.shape[0]\n",
        "\n",
        "\n",
        "    if n_components > 1 and len(np.unique(labels)) > 1:\n",
        "        silhouette = silhouette_score(X, labels)\n",
        "        db_index = davies_bouldin_score(X, labels)\n",
        "    else:\n",
        "        silhouette, db_index = 0, float('inf')\n",
        "\n",
        "\n",
        "    print(\"\\n===== GMM Performance Metrics =====\")\n",
        "    print(f\"Number of components: {n_components}\")\n",
        "    print(f\"Covariance type: {gmm.covariance_type}\")\n",
        "    print(f\"BIC: {bic:.2f}\")\n",
        "    print(f\"AIC: {aic:.2f}\")\n",
        "    print(f\"Log Likelihood: {log_likelihood:.2f}\")\n",
        "    if n_components > 1 and len(np.unique(labels)) > 1:\n",
        "        print(f\"Silhouette Score: {silhouette:.4f}\")\n",
        "        print(f\"Davies-Bouldin Index: {db_index:.4f}\")\n",
        "    else:\n",
        "        print(\"Silhouette Score: Not applicable\")\n",
        "        print(\"Davies-Bouldin Index: Not applicable\")\n",
        "\n",
        "    if y is not None:\n",
        "        ari_score = adjusted_rand_score(y, labels)\n",
        "        print(f\"Adjusted Rand Index (ARI): {ari_score:.4f}\")\n",
        "\n",
        "    return gmm, n_components\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    from pre_processing import preprocess_wine_data\n",
        "\n",
        "\n",
        "    wine_path = 'wine.data'\n",
        "\n",
        "    print(\"Using Wine dataset...\")\n",
        "    X, y, _, _ = preprocess_wine_data(wine_path)\n",
        "\n",
        "\n",
        "    try:\n",
        "        n_components = 4\n",
        "        wine_gmm, wine_n_components = train_evaluate_gmm(\n",
        "            X,\n",
        "            dataset_name='Wine',\n",
        "            y=y,\n",
        "            n_components=n_components\n",
        "        )\n",
        "\n",
        "    except NameError:\n",
        "        print(\"Wine dataset not found. Make sure to run preprocessing first.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8wotdE8b44z",
        "outputId": "8f30f192-fb9b-4fed-84cc-312f69fcfcc2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Wine dataset...\n",
            "Loading Wine dataset...\n",
            "Wine dataset shape: (178, 14)\n",
            "First few rows of the wine dataset:\n",
            "   Class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
            "0      1    14.23        1.71  2.43               15.6        127   \n",
            "1      1    13.20        1.78  2.14               11.2        100   \n",
            "2      1    13.16        2.36  2.67               18.6        101   \n",
            "3      1    14.37        1.95  2.50               16.8        113   \n",
            "4      1    13.24        2.59  2.87               21.0        118   \n",
            "\n",
            "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
            "0           2.80        3.06                  0.28             2.29   \n",
            "1           2.65        2.76                  0.26             1.28   \n",
            "2           2.80        3.24                  0.30             2.81   \n",
            "3           3.85        3.49                  0.24             2.18   \n",
            "4           2.80        2.69                  0.39             1.82   \n",
            "\n",
            "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
            "0             5.64  1.04                          3.92     1065  \n",
            "1             4.38  1.05                          3.40     1050  \n",
            "2             5.68  1.03                          3.17     1185  \n",
            "3             7.80  0.86                          3.45     1480  \n",
            "4             4.32  1.04                          2.93      735  \n",
            "\n",
            "Performing outlier removal...\n",
            "Removed 9 outliers\n",
            "Clean wine dataset shape: (169, 13)\n",
            "\n",
            "Performing feature scaling...\n",
            "\n",
            "Performing PCA dimensionality reduction...\n",
            "Reduced dimensions: 10 components explain 95% of variance\n",
            "Explained variance ratio: [0.38273714 0.20387307 0.09914071 0.06493513 0.05911935 0.04680614\n",
            " 0.03847304 0.02627262 0.02249277 0.02038877]\n",
            "\n",
            "===== Training GMM on Wine Dataset =====\n",
            "\n",
            "===== GMM Performance Metrics =====\n",
            "Number of components: 4\n",
            "Covariance type: full\n",
            "BIC: 4933.39\n",
            "AIC: 4110.23\n",
            "Log Likelihood: -1792.11\n",
            "Silhouette Score: 0.2510\n",
            "Davies-Bouldin Index: 1.7301\n",
            "Adjusted Rand Index (ARI): 0.7588\n"
          ]
        }
      ]
    }
  ]
}